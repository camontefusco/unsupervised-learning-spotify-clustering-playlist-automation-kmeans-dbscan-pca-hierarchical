{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a3763a",
   "metadata": {},
   "source": [
    "# 4 — PCA for Music Features (Theory + Interpretation)\n",
    "\n",
    "**Goal:** Understand and *use* PCA to visualize Spotify audio features, reduce noise/correlation, and interpret the main axes of variation.\n",
    "\n",
    "**You’ll learn:**\n",
    "- Intuition: what PCA optimizes (variance) and why it helps clustered data\n",
    "- How to read **explained variance** (scree & cumulative plots)\n",
    "- How to **interpret loadings** (which features make up PC1/PC2)\n",
    "- Visualize K-Means clusters in 2D PCA space and connect to *moods/playlists*\n",
    "\n",
    "> We keep PCA for **visualization & interpretation**. We do **not** force clustering in PCA space here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe2b51",
   "metadata": {},
   "source": [
    "## 0) Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e46d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "RNG = np.random.RandomState(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c8ae2",
   "metadata": {},
   "source": [
    "## 1) Load data (and optional precomputed clusters)\n",
    "Expected CSV: `../data/spotify_5000_songs.csv`\n",
    "\n",
    "**Tip:** If you already ran the K-Means notebook, we’ll try to load `../reports/kmeans20_quantile_assignments.csv` so we can color points by cluster. Otherwise, we’ll compute a quick KMeans@20 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA = Path(\"../data/spotify_5000_songs.csv\")\n",
    "assert DATA.exists(), f\"Missing data file at {DATA}. Place your CSV there.\"\n",
    "\n",
    "def clean_col(c):\n",
    "    s = re.sub(r\"\\s+\", \" \", str(c)).strip()\n",
    "    return s.split(\" \")[0]\n",
    "\n",
    "df_raw = pd.read_csv(DATA)\n",
    "df = df_raw.copy()\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "FEATURES = ['danceability','energy','acousticness','instrumentalness','liveness','valence',\n",
    "            'tempo','speechiness','loudness','duration_ms','key','mode','time_signature']\n",
    "available = [c for c in FEATURES if c in df.columns]\n",
    "X = df[available].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "print(\"Using features:\", available, \"| Shape:\", X.shape)\n",
    "\n",
    "assign_path = Path(\"../reports/kmeans20_quantile_assignments.csv\")\n",
    "labels = None\n",
    "if assign_path.exists():\n",
    "    df_assign = pd.read_csv(assign_path)\n",
    "    if 'cluster' in df_assign.columns and len(df_assign)==len(df):\n",
    "        labels = df_assign['cluster'].values[:len(X)]\n",
    "        print(\"Loaded clusters from:\", assign_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1328c",
   "metadata": {},
   "source": [
    "## 2) Why PCA? (Intuition)\n",
    "- Many audio features are **correlated** (e.g., energy & loudness). PCA finds new axes (PCs) that are **uncorrelated** and capture the most variance.\n",
    "- PC1 captures the largest direction of variation; PC2 the next largest **orthogonal** direction, etc.\n",
    "- This is useful for: plotting in 2D, de-noising, and understanding the *main musical dimensions* (e.g., **energy** vs **valence**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26e3ac",
   "metadata": {},
   "source": [
    "## 3) Scale features before PCA\n",
    "To avoid features with large ranges dominating, we’ll scale. We’ll use **QuantileTransformer** (good for skew). You can toggle to **StandardScaler** to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_quantile = True\n",
    "\n",
    "if use_quantile:\n",
    "    scaler = QuantileTransformer(output_distribution='normal', n_quantiles=min(1000, len(X)), random_state=42)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de6c3a",
   "metadata": {},
   "source": [
    "## 4) Fit PCA and inspect explained variance\n",
    "**Explained variance ratio** tells us how much of the dataset's variability each PC captures. Use the **scree plot** to spot elbows and the **cumulative** curve to see how many PCs explain, say, 80–95% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b26098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit more PCs than 2 so we can inspect variance structure\n",
    "n_components = min(12, X_scaled.shape[1])\n",
    "pca = PCA(n_components=n_components, random_state=42).fit(X_scaled)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "cum = explained.cumsum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, n_components+1), explained, marker='o')\n",
    "ax.set_xlabel('PC'); ax.set_ylabel('Explained variance ratio')\n",
    "ax.set_title('Scree plot')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, n_components+1), cum, marker='o')\n",
    "ax.axhline(0.8, linestyle='--'); ax.axhline(0.9, linestyle='--')\n",
    "ax.set_xlabel('PC'); ax.set_ylabel('Cumulative explained variance')\n",
    "ax.set_title('Cumulative variance')\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({\n",
    "    'PC': [f'PC{i}' for i in range(1, n_components+1)],\n",
    "    'explained_ratio': explained,\n",
    "    'cumulative_ratio': cum\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f354a0",
   "metadata": {},
   "source": [
    "## 5) Interpret PC loadings (feature contributions)\n",
    "**Loadings** indicate how each original feature contributes to a PC. Large positive/negative values mean strong influence.\n",
    "Interpreting PC1/PC2 helps translate axes into musical language (e.g., PC1 ~ energy/loudness → ‘intensity axis’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59054b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "                        index=X.columns[:pca.components_.shape[1]],\n",
    "                        columns=[f'PC{i}' for i in range(1, n_components+1)])\n",
    "# Show top magnitudes for PC1 and PC2\n",
    "def top_loadings(pc, n=8):\n",
    "    s = loadings[pc].abs().sort_values(ascending=False).head(n).index\n",
    "    return loadings.loc[s, pc].sort_values(ascending=False)\n",
    "\n",
    "top_pc1 = top_loadings('PC1', 8)\n",
    "top_pc2 = top_loadings('PC2', 8)\n",
    "\n",
    "print(\"Top PC1 loadings:\")\n",
    "display(top_pc1)\n",
    "print(\"\\nTop PC2 loadings:\")\n",
    "display(top_pc2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15108a30",
   "metadata": {},
   "source": [
    "### Optional: bar plots of PC1/PC2 loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for pc in ['PC1','PC2']:\n",
    "    s = loadings[pc].sort_values()\n",
    "    plt.figure(figsize=(8,4))\n",
    "    s.plot(kind='barh')\n",
    "    plt.title(f'{pc} loadings (all features)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150347a2",
   "metadata": {},
   "source": [
    "## 6) 2D PCA projection colored by cluster\n",
    "If we have labels (from K-Means k=20), we’ll color by cluster to *see* separation. If not, we’ll quickly compute K-Means here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862122b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X2 = PCA(n_components=2, random_state=42).fit_transform(X_scaled)\n",
    "\n",
    "if labels is None:\n",
    "    km = KMeans(n_clusters=20, n_init=10, random_state=42).fit(X_scaled)\n",
    "    labels = km.labels_\n",
    "    print(\"No precomputed labels found; computed KMeans(k=20) on the fly.\")\n",
    "\n",
    "plt.scatter(X2[:,0], X2[:,1], c=labels, s=5)\n",
    "plt.title('PCA 2D — colored by K-Means cluster')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ef37c",
   "metadata": {},
   "source": [
    "**How to read this map**\n",
    "- **Islands/blobs** of one color suggest clear playlist ‘moods’.\n",
    "- **Bridges** or mixed regions might be transitional tracks.\n",
    "- If everything overlaps, consider different scaling, features, or algorithms (e.g., Agglomerative)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6efb7b9",
   "metadata": {},
   "source": [
    "## 7) Save PCA outputs for reuse\n",
    "These can be included in your README or slides and help with reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96307d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT = Path(\"../reports\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save 2D projection and labels (if present)\n",
    "pca_df = pd.DataFrame({'PC1': X2[:,0], 'PC2': X2[:,1], 'cluster': labels})\n",
    "pca_path = OUT / \"pca2_projection_kmeans20.csv\"\n",
    "pca_df.to_csv(pca_path, index=False)\n",
    "\n",
    "print(f\"Saved: {pca_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd453d",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Takeaways\n",
    "- PCA reveals **major axes of musical variation** (often energy/loudness vs. valence/tempo).\n",
    "- Use **explained variance** to decide how many PCs you need for visualization/reporting (not for clustering here).\n",
    "- Loadings **translate math → music**: they tell you what each axis means.\n",
    "- The 2D PCA map is a great storytelling tool for Moosic editors and stakeholders."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
