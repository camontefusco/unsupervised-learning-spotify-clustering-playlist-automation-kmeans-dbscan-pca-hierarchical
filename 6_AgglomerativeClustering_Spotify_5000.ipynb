{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6cc272",
   "metadata": {},
   "source": [
    "# 6 — Agglomerative (Hierarchical) Clustering on Spotify (Beginner-Friendly)\n",
    "\n",
    "**Goal:** Explore hierarchical clustering for playlist prototyping. Compare linkages, visualize clusters, and (optionally) inspect a dendrogram.\n",
    "\n",
    "**You’ll learn:**\n",
    "- How **Agglomerative** builds a hierarchy (bottom-up merges)\n",
    "- What **linkage** means (ward / average / complete) and when to use each\n",
    "- How to evaluate k=20 clusters with **Silhouette / Davies–Bouldin / Calinski–Harabasz**\n",
    "- How to plot the result in **PCA 2D** and (optionally) a **dendrogram** on a subsample\n",
    "\n",
    "> Hierarchical clustering is great for **editorial workflows**: you can choose how deep to cut the tree to get your playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca05a1e",
   "metadata": {},
   "source": [
    "## 0) Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# Optional dendrogram (requires SciPy). If missing, install via requirements and rerun.\n",
    "try:\n",
    "    from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "    SCIPY_OK = True\n",
    "except Exception:\n",
    "    SCIPY_OK = False\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7,5)\n",
    "RNG = np.random.RandomState(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbce1c72",
   "metadata": {},
   "source": [
    "## 1) Load and prepare the data\n",
    "We clean column names and select Spotify audio features used across the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA = Path(\"../data/spotify_5000_songs.csv\")\n",
    "assert DATA.exists(), f\"Missing data at {DATA}. Place your CSV there.\"\n",
    "\n",
    "def clean_col(c):\n",
    "    s = re.sub(r\"\\s+\", \" \", str(c)).strip()\n",
    "    return s.split(\" \")[0]\n",
    "\n",
    "df_raw = pd.read_csv(DATA)\n",
    "df = df_raw.copy()\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n",
    "FEATURES = ['danceability','energy','acousticness','instrumentalness','liveness','valence',\n",
    "            'tempo','speechiness','loudness','duration_ms','key','mode','time_signature']\n",
    "available = [c for c in FEATURES if c in df.columns]\n",
    "X = df[available].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "print('Using features:', available, '| Shape:', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460c4fb",
   "metadata": {},
   "source": [
    "## 2) Scale features\n",
    "Ward linkage (variance-minimizing) is particularly sensitive to scaling. We’ll default to **QuantileTransformer** (good for skew)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b970f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_quantile = True\n",
    "\n",
    "if use_quantile:\n",
    "    scaler = QuantileTransformer(output_distribution='normal', n_quantiles=min(1000, len(X)), random_state=42)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "Xt = scaler.fit_transform(X)\n",
    "Xt[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25bbf3c",
   "metadata": {},
   "source": [
    "## 3) What does *linkage* mean?\n",
    "- **ward**: merges that minimize increase in within-cluster variance → favors compact, spherical clusters (K-Means-like)\n",
    "- **average**: merges based on average distance between points across clusters → tolerant to shape, less sensitive to outliers than complete\n",
    "- **complete**: merges using the **max** pairwise distance → tends to produce tighter, chained clusters\n",
    "\n",
    "We’ll compare **k=20** clusters across these linkages and score them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfccf4fb",
   "metadata": {},
   "source": [
    "## 4) Evaluate linkages at **k=20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_metrics(Xt, labels):\n",
    "    uniq = set(labels)\n",
    "    if len(uniq) < 2:\n",
    "        return {'silhouette': None, 'davies_bouldin': None, 'calinski_harabasz': None}\n",
    "    return {\n",
    "        'silhouette': float(silhouette_score(Xt, labels)),\n",
    "        'davies_bouldin': float(davies_bouldin_score(Xt, labels)),\n",
    "        'calinski_harabasz': float(calinski_harabasz_score(Xt, labels)),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for link in ['ward','average','complete']:\n",
    "    # ward requires Euclidean distance and is only defined for numeric features (we have that)\n",
    "    model = AgglomerativeClustering(n_clusters=20, linkage=link)\n",
    "    labels = model.fit_predict(Xt)\n",
    "    met = safe_metrics(Xt, labels)\n",
    "    rows.append({'linkage': link, **met})\n",
    "\n",
    "df_link = pd.DataFrame(rows).sort_values('silhouette', ascending=False)\n",
    "df_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d311c54",
   "metadata": {},
   "source": [
    "**How to read this table**\n",
    "- **Higher Silhouette / Calinski–Harabasz** and **lower Davies–Bouldin** are better\n",
    "- If **ward** is top: your clusters are closer to spherical (K-Means-like)\n",
    "- If **average/complete** improve: your data might have elongated or chained shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52a1eb",
   "metadata": {},
   "source": [
    "## 5) Visualize the best linkage on a PCA 2D map\n",
    "We’ll pick the best row by Silhouette and plot the clusters in 2D PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef022c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick the best linkage by silhouette (fallback to ward if all are None)\n",
    "best_link = df_link.dropna(subset=['silhouette']).head(1)['linkage'].iloc[0] if df_link['silhouette'].notna().any() else 'ward'\n",
    "print(\"Best linkage:\", best_link)\n",
    "\n",
    "# Fit best model\n",
    "best_model = AgglomerativeClustering(n_clusters=20, linkage=best_link)\n",
    "labels = best_model.fit_predict(Xt)\n",
    "\n",
    "# 2D PCA projection for visualization only\n",
    "P2 = PCA(n_components=2, random_state=42).fit_transform(Xt)\n",
    "plt.scatter(P2[:,0], P2[:,1], c=labels, s=5)\n",
    "plt.title(f'Agglomerative ({best_link}, k=20) — PCA 2D')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d21112",
   "metadata": {},
   "source": [
    "**Reading the plot**\n",
    "- Tighter color islands → clearer cluster separation\n",
    "- Mixed colors → consider a different linkage or number of clusters\n",
    "- Compare this to your **K-Means** PCA plot — is hierarchy separating genres/moods more intuitively?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bab8fc",
   "metadata": {},
   "source": [
    "## 6) (Optional) Dendrogram on a subsample\n",
    "A dendrogram shows how clusters merge **step-by-step**. It’s great for storytelling with editors.\n",
    "\n",
    "**Note:** For speed/readability we use a **subsample** and **truncate** the tree to top levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SCIPY_OK:\n",
    "    n = min(1500, len(Xt))  # subsample for readability/performance\n",
    "    idx = RNG.choice(len(Xt), size=n, replace=False)\n",
    "    Xs = Xt[idx]\n",
    "\n",
    "    # Ward linkage for dendrogram (works nicely with scaled numeric features)\n",
    "    Z = linkage(Xs, method='ward')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    dendrogram(Z, truncate_mode='level', p=10)  # show top 10 merge levels\n",
    "    plt.title('Agglomerative (Ward) — Dendrogram (truncated)')\n",
    "    plt.xlabel('Sample index/cluster'); plt.ylabel('Distance')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SciPy not available; install scipy>=1.10 and rerun to see the dendrogram.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab316e82",
   "metadata": {},
   "source": [
    "## 7) Save metrics for your report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d33057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT = Path(\"../reports\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "out_path = OUT / \"agglomerative_linkage_k20.csv\"\n",
    "df_link.to_csv(out_path, index=False)\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080621c6",
   "metadata": {},
   "source": [
    "---\n",
    "## 8) Takeaways for Moosic\n",
    "- **Ward** often matches K-Means in spirit (compact, centroid-like clusters)\n",
    "- **Average/Complete** can surface different structures (useful if moods are chained/gradual)\n",
    "- The **hierarchy** helps editors decide how granular playlists should be (cut higher → fewer playlists; cut lower → more specialized moods)\n",
    "\n",
    "**Recommendation:** Keep both **K-Means** (fast, simple) and **Agglomerative** (explainable hierarchy) in your toolkit. Use whichever yields clearer mood islands for a given dataset."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
